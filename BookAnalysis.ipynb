{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgslFm7Ad47ddtDVHFMwlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-disha/Gutenberg-book-analysis/blob/master/BookAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oJsoqpv3ZAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "96448f90-a97d-44b3-c3b5-f96b5c6acaa7"
      },
      "source": [
        "!pip install roman\n",
        "import roman\n",
        "import random\n",
        "class BookAnalysis():\n",
        "    def __init__(self, file):\n",
        "        with open(file) as f:\n",
        "            self.read_lines = f.readlines()\n",
        "        self.count_words()\n",
        "    def count_words(self):\n",
        "        self.word_count_chapwise = {}\n",
        "        with open(\"1-1000.txt\") as f:\n",
        "            self.stopwords = set([s.lower() for s in f.read().split()[:100]])\n",
        "        with open(\"chapter.txt\") as f:\n",
        "            self.chapters = set(f.readlines())\n",
        "        curr_chap = 1\n",
        "        self.word_dict = {}\n",
        "        prev_word = \"\"\n",
        "        self.chapter_text = {}\n",
        "        for line in self.read_lines :\n",
        "            if line in self.chapters :\n",
        "                curr_chap = roman.fromRoman(line.split()[1].strip(\".\\n\"))\n",
        "            else :\n",
        "                self.word_count_chapwise[curr_chap] = self.word_count_chapwise.get(curr_chap, {})\n",
        "                self.chapter_text[curr_chap] = self.chapter_text.get(curr_chap, \"\") + line\n",
        "                for word in line.split():\n",
        "                    word = word.replace(\".\",\"\")\n",
        "                    word = word.replace(\",\",\"\")\n",
        "                    word = word.replace(\":\",\"\")\n",
        "                    word = word.replace(\"\\\"\",\"\")\n",
        "                    word = word.replace(\"!\",\"\")\n",
        "                    word = word.replace(\"â€œ\",\"\")\n",
        "                    word = word.replace(\"â€˜\",\"\")\n",
        "                    word = word.replace(\"*\",\"\")\n",
        "                    word = word.replace(\"?\",\"\")\n",
        "                    word = word.replace(\"-\",\"\")\n",
        "                    word = word.replace(\"_\",\"\")\n",
        "                    if prev_word not in self.word_dict :\n",
        "                        self.word_dict[prev_word] = []\n",
        "                    self.word_dict[prev_word].append(word)\n",
        "                    word_count = self.word_count_chapwise[curr_chap]\n",
        "                    word_count[word] = word_count.get(word, 0) + 1\n",
        "                    prev_word = word\n",
        "        self.sorted_word_count = {}\n",
        "        for chap in self.word_count_chapwise.keys():\n",
        "            for word in self.word_count_chapwise[chap]:\n",
        "                self.sorted_word_count[word] = self.sorted_word_count.get(word, 0) + self.word_count_chapwise[chap][word]\n",
        "        self.sorted_word_count = sorted(self.sorted_word_count.items(), key=lambda x : -x[1])\n",
        "    def getTotalNumberOfWords(self):\n",
        "        file = open('996.txt')\n",
        "        data = file.read()\n",
        "        words = data.lower().split()\n",
        "        return len(words)\n",
        "    def getTotalUniqueWords(self):\n",
        "        unique = set()\n",
        "        for chap in self.word_count_chapwise.keys():\n",
        "            for word in self.word_count_chapwise[chap]:\n",
        "                unique.add(word)\n",
        "        return len(unique)\n",
        "    def get20MostFrequentWords(self):\n",
        "        return self.sorted_word_count[:20]\n",
        "    def get20MostInterestingFrequentWords(self):\n",
        "        interesting_words = []\n",
        "        for pair in self.sorted_word_count:\n",
        "            if pair[0] not in self.stopwords and len(interesting_words) < 20:\n",
        "                interesting_words.append(pair)\n",
        "        return interesting_words\n",
        "    def get20LeastFrequentWords(self):\n",
        "        return self.sorted_word_count[::-1][:20]\n",
        "    def getFrequencyOfWord(self, word):\n",
        "        sorted_keys = sorted(self.word_count_chapwise.keys())\n",
        "        freq = []\n",
        "        for chapter in sorted_keys :\n",
        "            freq.append(self.word_count_chapwise[chapter].get(word, 0))\n",
        "        return freq\n",
        "    def getChapterQuoteAppears(self, quote):\n",
        "        for chapter in self.chapter_text :\n",
        "            if self.chapter_text[chapter].find(quote) >= 0 :\n",
        "                return chapter\n",
        "        return -1\n",
        "    def generateSentence(self):\n",
        "        word = \"The\"\n",
        "        sentence = word\n",
        "        choices = self.word_dict\n",
        "        for i in range(20):\n",
        "            word = random.choice(choices[word])\n",
        "            sentence += \" \" + word\n",
        "        return sentence\n",
        "book1 = BookAnalysis(\"996.txt\")\n",
        "print(book1.getTotalNumberOfWords())\n",
        "print(book1.getTotalUniqueWords())\n",
        "print(book1.get20MostFrequentWords())\n",
        "print(book1.get20MostInterestingFrequentWords())\n",
        "print(book1.get20LeastFrequentWords())\n",
        "print(book1.getFrequencyOfWord(\"Christian\"))\n",
        "print(book1.getChapterQuoteAppears(\"the work of fame that mortals desire\"))\n",
        "print(book1.generateSentence())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: roman in /usr/local/lib/python3.6/dist-packages (3.3)\n",
            "425889\n",
            "21252\n",
            "[('the', 20793), ('and', 16923), ('to', 13478), ('of', 12846), ('that', 7601), ('a', 6954), ('in', 6865), ('I', 6328), ('he', 5726), ('it', 5101), ('for', 4844), ('his', 4567), ('as', 4261), ('is', 3713), ('was', 3583), ('not', 3565), ('with', 3518), ('him', 3368), ('be', 3232), ('my', 2721)]\n",
            "[('I', 6328), ('Don', 2623), ('me', 2366), ('Sancho', 1868), ('Quixote', 1848), ('thou', 1135), ('The', 939), ('say', 875), ('any', 866), ('good', 820), ('himself', 806), ('such', 787), ('am', 726), ('thee', 721), ('without', 714), ('made', 672), ('those', 663), ('upon', 658), ('should', 639), ('us', 630)]\n",
            "[('Farewell', 1), ('doomed', 1), ('sally;', 1), ('mouldering', 1), ('frozen', 1), ('knight;no', 1), ('illtrimmed', 1), ('Tordesillesque', 1), ('Adventure', 1), ('weaklings;', 1), ('storytellers', 1), ('presumptuous', 1), ('shelf', 1), ('wire', 1), ('Rest', 1), ('scared;', 1), ('cared;', 1), ('quail', 1), ('tomb;', 1), ('contended', 1)]\n",
            "[3, 0, 2, 1, 0, 1, 0, 3, 0, 0, 1, 1, 2, 0, 0, 2, 2, 2, 2, 0, 4, 1, 0, 1, 1, 1, 6, 1, 1, 0, 0, 1, 0, 1, 0, 2, 5, 0, 0, 17, 22, 1, 0, 0, 1, 1, 3, 2, 1, 0, 1, 2, 1, 2, 2, 1, 0, 2, 0, 0, 0, 0, 11, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "8\n",
            "The crow's illboding croak the living death or to God exalteth; and gave him leave him We hear of a fool\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}